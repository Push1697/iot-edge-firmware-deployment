# Edge Observability Optimization Project

## ðŸ” Project Overview
This project focuses on deploying and optimizing a resource-constrained observability stack for an edge computing robot (2-core CPU, 500 MB RAM). 
The goal was to take a "buggy" Python sensor service and a heavy Prometheus/Grafana stack, and transform it into a lightweight, stable, and observable system using **Docker** and **VictoriaMetrics**.

### ðŸŽ¯ Objectives
- **Containerize** the Python service efficiently (Alpine).
- **Optimize** usage to fit within a strict **300 MB RAM budget**.
- **Fix** performance bottlenecks (CPU burns, memory leaks).
- **Implement** a lightweight monitoring solution.

---

## ðŸ› ï¸ Key Changes & Optimizations

### 1. ðŸ³ Docker Constraints (Task 3.1 & 3.5)
- **Base Image Switched**: Migrated from `python:3.10` (~900MB) to `python:3.10-alpine` (~50MB).
- **Resource Limits**: Applied strict limits in `docker-compose.yml` to prevent Out-Of-Memory (OOM) crashes affecting the host.
    - `sensor-service`: **50MB** RAM / 0.5 CPU.
    - `victoriametrics`: **150MB** RAM / 0.5 CPU.

### 2. ðŸ“‰ Architecture Overhaul (Task 3.2 & 3.3)
We moved from a heavyweight stack to a single-binary edge stack.

| Feature | Old Stack | New Stack (Edge Optimized) | Benefit |
| :--- | :--- | :--- | :--- |
| **Collector** | Prometheus | **VictoriaMetrics** | -66% RAM usage, better compression. |
| **Visualization** | Grafana | **VMUI (Built-in)** | Removed 200MB dependency. |
| **Storage** | High Disk I/O | Optimized LSM Tree | Extended SD card life. |

### 3. ðŸ Code Level Optimizations
We analyzed `sensor_service.py` and applied the following fixes:
- **CPU Burn**: Removed a `for` loop that iterated 2 million times per request.
    - *Result*: Scrape duration dropped from seconds to milliseconds.
- **Custom Metric**: Added `SCRAPE_DURATION` (Histogram) to rigorously measure internal processing time.
- **Memory**: While the 5MB `data_blob` leak remains (for demonstration purposes), the container limits now strictly contain it.

---

## ðŸ”§ Troubleshooting & Debugging

During the implementation, we encountered specific compatibility issues between Prometheus configuration files and VictoriaMetrics.

### 1. `evaluation_interval` Compatibility
VictoriaMetrics supports standard `prometheus.yml` configs, but flags certain global settings like `evaluation_interval` as warnings or errors if not handled, as it focuses on scraping.

**The Fix**:
We leveraged the strict parsing flag in the VictoriaMetrics command arguments to allow it to ignore unsupported fields without crashing.

Inside `docker-compose.yml`:
```yaml
command:
  # ...
  - "-promscrape.config.strictParse=false" 
```

*Note: Alternatively, `evaluation_interval` can be commented out in `prometheus.yml` as it is primarily a Prometheus-server specific setting for recording rules, which we are not using extensively here.*

### 2. Debugging Scrape Failures
**Symptom**: Intermittent timeouts when scraping `/metrics`.
**Root Cause**: The Python Global Interpreter Lock (GIL) and single-threaded Flask app were blocked by the CPU burn loop.
**Solution**:
1.  Added `SCRAPE_DURATION` metric.
2.  Observed buckets showing > 2.0s latency.
3.  Removed the CPU loop -> Latency dropped to < 0.01s.

---

## ðŸš€ How to Run

1.  **Start the Stack**:
    ```bash
    docker-compose up -d --build
    ```

2.  **Access Components**:
    - **Sensor Metrics**: `http://localhost:8000/metrics`
    - **VictoriaMetrics UI**: `http://localhost:8428/vmui`
        - Go to "Dashboards" or "Explore" to query `sensor_scrape_duration_seconds_bucket`.

3.  **Verify Stats**:
    ```bash
    docker stats
    ```
    Ensure total usage is < 300MB.

---

## ðŸ“Š Repository Structure
- `sensor_service.py`: Optimized Python application.
- `docker-compose.yml`: Final deployment file with limits.
- `Dockerfile`: Multi-stage Alpine build.
- `OPTIMIZATION_SUMMARY.md`: Detailed performance report with graphs.
- `images/`: Screenshots of analysis and improvements.